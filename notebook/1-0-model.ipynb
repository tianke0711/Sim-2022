{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b64c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "from tqdm import tqdm_notebook\n",
    "from uuid import uuid4\n",
    "\n",
    "## Torch Modules\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ab6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(seq_1, max_seq_length = 140, zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
    "    ## Tokenzine Input\n",
    "    \n",
    "    tokens_a = tokenizer.tokenize(seq_1)\n",
    "\n",
    "    ## Truncate\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "    ## Initialize Tokens\n",
    "    tokens = []\n",
    "    if include_CLS_token:\n",
    "        tokens.append(tokenizer.cls_token)\n",
    "    ## Add Tokens and separators\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "\n",
    "    if include_SEP_token:\n",
    "        tokens.append(tokenizer.sep_token)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    ## Input Mask \n",
    "    input_mask = [1] * len(input_ids)\n",
    "    if zero_pad:\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "    return torch.tensor(input_ids).unsqueeze(0), input_mask\n",
    "                     \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "282360bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        utterance = self.data.text[index]\n",
    "        label = self.data.label[index]\n",
    "        X, _  = prepare_features(utterance)\n",
    "        y = label_to_inx[self.data.label[index]]\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(pred, lst_true):\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "     \n",
    "    acc = accuracy_score(lst_true, pred)\n",
    "    f1_micro = f1_score(lst_true, pred, average='micro')\n",
    "    f1_macro = f1_score(lst_true, pred, average='macro')\n",
    "    \n",
    "    return acc, f1_micro, f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee17e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_inx = {'unsustainable':0,'sustainable':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f4c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10323ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if errors: /tmp/.cache/torch permission just give sudo chmod -R a+rw xxx/xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395c6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2fc06dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf9f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b615cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0467d7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cf1d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_valid = pd.read_csv('../data/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe88ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b54805d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Intents(df_train)\n",
    "testing_set = Intents(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58af30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 16,\n",
    "          'shuffle': True,\n",
    "          'drop_last': False,\n",
    "          'num_workers': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97a61696",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_set, **params)\n",
    "testing_loader = DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86f48741",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-05\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3961870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "inp = training_set.__getitem__(0)[0].cuda()\n",
    "output = model(inp)[0]\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a00cd4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd78aabeaa4441ccb9fa12210be217ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n",
      "Iteration: 0. Loss: 0.1651824712753296. Accuracy: 47.36842105263158%\n",
      "Iteration: 100. Loss: 0.48423951864242554. Accuracy: 47.36842105263158%\n",
      "Iteration: 200. Loss: 0.8175522089004517. Accuracy: 55.26315789473684%\n",
      "Iteration: 300. Loss: 0.6403018832206726. Accuracy: 48.49624060150376%\n",
      "Iteration: 400. Loss: 0.5755423307418823. Accuracy: 53.00751879699248%\n",
      "Iteration: 500. Loss: 0.9929331541061401. Accuracy: 51.12781954887218%\n",
      "Iteration: 600. Loss: 0.6193049550056458. Accuracy: 51.8796992481203%\n",
      "Iteration: 700. Loss: 0.3519832193851471. Accuracy: 52.63157894736842%\n",
      "Iteration: 800. Loss: 0.4879077672958374. Accuracy: 52.255639097744364%\n",
      "Iteration: 900. Loss: 0.7298197150230408. Accuracy: 51.12781954887218%\n",
      "Iteration: 1000. Loss: 0.4408475160598755. Accuracy: 52.63157894736842%\n",
      "Iteration: 1100. Loss: 0.8674148321151733. Accuracy: 55.26315789473684%\n",
      "Iteration: 1200. Loss: 0.8232302069664001. Accuracy: 53.7593984962406%\n",
      "Iteration: 1300. Loss: 0.7793020009994507. Accuracy: 49.24812030075188%\n",
      "Iteration: 1400. Loss: 0.8731143474578857. Accuracy: 47.36842105263158%\n",
      "Iteration: 1500. Loss: 0.6143587827682495. Accuracy: 53.00751879699248%\n",
      "Iteration: 1600. Loss: 0.5295650959014893. Accuracy: 52.63157894736842%\n",
      "Iteration: 1700. Loss: 0.844173789024353. Accuracy: 46.61654135338346%\n",
      "Iteration: 1800. Loss: 0.4618929922580719. Accuracy: 53.38345864661654%\n",
      "Iteration: 1900. Loss: 0.581564724445343. Accuracy: 49.62406015037594%\n",
      "EPOCH -- 1\n",
      "Iteration: 0. Loss: 0.8889561891555786. Accuracy: 51.50375939849624%\n",
      "Iteration: 100. Loss: 0.7273995280265808. Accuracy: 52.255639097744364%\n",
      "Iteration: 200. Loss: 0.8217156529426575. Accuracy: 47.744360902255636%\n",
      "Iteration: 300. Loss: 1.05182945728302. Accuracy: 53.00751879699248%\n",
      "Iteration: 400. Loss: 0.3779853284358978. Accuracy: 52.255639097744364%\n",
      "Iteration: 500. Loss: 0.711212158203125. Accuracy: 69.92481203007519%\n",
      "Iteration: 600. Loss: 0.4785984754562378. Accuracy: 50.75187969924812%\n",
      "Iteration: 700. Loss: 0.8603276014328003. Accuracy: 64.66165413533835%\n",
      "Iteration: 800. Loss: 0.5679144859313965. Accuracy: 78.19548872180451%\n",
      "Iteration: 900. Loss: 0.08431687951087952. Accuracy: 59.774436090225564%\n",
      "Iteration: 1000. Loss: 0.8612818121910095. Accuracy: 71.42857142857143%\n",
      "Iteration: 1100. Loss: 0.31999385356903076. Accuracy: 60.526315789473685%\n",
      "Iteration: 1200. Loss: 0.1216462105512619. Accuracy: 63.53383458646616%\n",
      "Iteration: 1300. Loss: 0.9836611151695251. Accuracy: 73.30827067669173%\n",
      "Iteration: 1400. Loss: 0.35112056136131287. Accuracy: 73.6842105263158%\n",
      "Iteration: 1500. Loss: 1.2210732698440552. Accuracy: 68.42105263157895%\n",
      "Iteration: 1600. Loss: 0.05196806415915489. Accuracy: 79.69924812030075%\n",
      "Iteration: 1700. Loss: 0.9311327338218689. Accuracy: 82.33082706766918%\n",
      "Iteration: 1800. Loss: 1.9623899459838867. Accuracy: 74.06015037593986%\n",
      "Iteration: 1900. Loss: 0.25893688201904297. Accuracy: 79.69924812030075%\n",
      "EPOCH -- 2\n",
      "Iteration: 0. Loss: 0.3263285160064697. Accuracy: 81.57894736842105%\n",
      "Iteration: 100. Loss: 0.26932013034820557. Accuracy: 76.69172932330827%\n",
      "Iteration: 200. Loss: 3.552307605743408. Accuracy: 83.0827067669173%\n",
      "Iteration: 300. Loss: 1.3651927709579468. Accuracy: 72.93233082706767%\n",
      "Iteration: 400. Loss: 0.14644892513751984. Accuracy: 74.06015037593986%\n",
      "Iteration: 500. Loss: 0.3186073303222656. Accuracy: 80.45112781954887%\n",
      "Iteration: 600. Loss: 0.12219167500734329. Accuracy: 60.150375939849624%\n",
      "Iteration: 700. Loss: 0.261702299118042. Accuracy: 67.29323308270676%\n",
      "Iteration: 800. Loss: 0.057263728231191635. Accuracy: 81.95488721804512%\n",
      "Iteration: 900. Loss: 1.1565054655075073. Accuracy: 80.07518796992481%\n",
      "Iteration: 1000. Loss: 0.12015899270772934. Accuracy: 73.6842105263158%\n",
      "Iteration: 1100. Loss: 0.15748879313468933. Accuracy: 83.0827067669173%\n",
      "Iteration: 1200. Loss: 0.324150413274765. Accuracy: 76.69172932330827%\n",
      "Iteration: 1300. Loss: 0.8051146864891052. Accuracy: 82.70676691729324%\n",
      "Iteration: 1400. Loss: 0.05917533487081528. Accuracy: 83.45864661654136%\n",
      "Iteration: 1500. Loss: 0.08508455753326416. Accuracy: 78.94736842105263%\n",
      "Iteration: 1600. Loss: 0.6705026030540466. Accuracy: 83.0827067669173%\n",
      "Iteration: 1700. Loss: 0.4304049611091614. Accuracy: 82.33082706766918%\n",
      "Iteration: 1800. Loss: 0.10243137925863266. Accuracy: 83.0827067669173%\n",
      "Iteration: 1900. Loss: 0.10566961020231247. Accuracy: 84.9624060150376%\n",
      "EPOCH -- 3\n",
      "Iteration: 0. Loss: 0.05068647116422653. Accuracy: 80.82706766917293%\n",
      "Iteration: 100. Loss: 1.541063666343689. Accuracy: 83.83458646616542%\n",
      "Iteration: 200. Loss: 0.05557052418589592. Accuracy: 74.81203007518798%\n",
      "Iteration: 300. Loss: 0.1829894483089447. Accuracy: 84.58646616541354%\n",
      "Iteration: 400. Loss: 0.6982684135437012. Accuracy: 83.83458646616542%\n",
      "Iteration: 500. Loss: 0.05325106903910637. Accuracy: 84.58646616541354%\n",
      "Iteration: 600. Loss: 0.04839562997221947. Accuracy: 85.33834586466165%\n",
      "Iteration: 700. Loss: 0.8203136920928955. Accuracy: 84.9624060150376%\n",
      "Iteration: 800. Loss: 0.2047303169965744. Accuracy: 83.83458646616542%\n",
      "Iteration: 900. Loss: 0.1622403860092163. Accuracy: 83.45864661654136%\n",
      "Iteration: 1000. Loss: 0.6376540660858154. Accuracy: 84.58646616541354%\n",
      "Iteration: 1100. Loss: 0.5009152889251709. Accuracy: 83.83458646616542%\n",
      "Iteration: 1200. Loss: 0.06863083690404892. Accuracy: 85.33834586466165%\n",
      "Iteration: 1300. Loss: 0.04338397830724716. Accuracy: 72.55639097744361%\n",
      "Iteration: 1400. Loss: 1.0281181335449219. Accuracy: 86.09022556390977%\n",
      "Iteration: 1500. Loss: 0.019932445138692856. Accuracy: 86.84210526315789%\n",
      "Iteration: 1600. Loss: 0.037586748600006104. Accuracy: 87.21804511278195%\n",
      "Iteration: 1700. Loss: 0.0539250522851944. Accuracy: 81.203007518797%\n",
      "Iteration: 1800. Loss: 0.017565635964274406. Accuracy: 88.7218045112782%\n",
      "Iteration: 1900. Loss: 0.15948091447353363. Accuracy: 79.32330827067669%\n",
      "EPOCH -- 4\n",
      "Iteration: 0. Loss: 0.03339296206831932. Accuracy: 83.83458646616542%\n",
      "Iteration: 100. Loss: 0.019287070259451866. Accuracy: 85.71428571428571%\n",
      "Iteration: 200. Loss: 0.014559338800609112. Accuracy: 79.69924812030075%\n",
      "Iteration: 300. Loss: 0.02045675925910473. Accuracy: 85.71428571428571%\n",
      "Iteration: 400. Loss: 0.019619571045041084. Accuracy: 84.9624060150376%\n",
      "Iteration: 500. Loss: 0.025526823475956917. Accuracy: 83.83458646616542%\n",
      "Iteration: 600. Loss: 0.018925217911601067. Accuracy: 83.83458646616542%\n",
      "Iteration: 700. Loss: 0.9029137492179871. Accuracy: 75.18796992481202%\n",
      "Iteration: 800. Loss: 0.24338839948177338. Accuracy: 87.21804511278195%\n",
      "Iteration: 900. Loss: 0.532268762588501. Accuracy: 84.21052631578948%\n",
      "Iteration: 1000. Loss: 0.04508550465106964. Accuracy: 84.21052631578948%\n",
      "Iteration: 1100. Loss: 0.12467716634273529. Accuracy: 85.33834586466165%\n",
      "Iteration: 1200. Loss: 0.011462309397757053. Accuracy: 87.59398496240601%\n",
      "Iteration: 1300. Loss: 0.022007301449775696. Accuracy: 87.59398496240601%\n",
      "Iteration: 1400. Loss: 0.0346754789352417. Accuracy: 85.71428571428571%\n",
      "Iteration: 1500. Loss: 0.012880932539701462. Accuracy: 85.33834586466165%\n",
      "Iteration: 1600. Loss: 0.028757551684975624. Accuracy: 75.56390977443608%\n",
      "Iteration: 1700. Loss: 0.016550157219171524. Accuracy: 88.7218045112782%\n",
      "Iteration: 1800. Loss: 0.028517523780465126. Accuracy: 86.84210526315789%\n",
      "Iteration: 1900. Loss: 0.05817944183945656. Accuracy: 87.59398496240601%\n",
      "EPOCH -- 5\n",
      "Iteration: 0. Loss: 0.02097858302295208. Accuracy: 81.95488721804512%\n",
      "Iteration: 100. Loss: 0.0074155074544250965. Accuracy: 87.96992481203007%\n",
      "Iteration: 200. Loss: 1.124558925628662. Accuracy: 87.21804511278195%\n",
      "Iteration: 300. Loss: 0.012379592284560204. Accuracy: 86.09022556390977%\n",
      "Iteration: 400. Loss: 1.0309754610061646. Accuracy: 83.0827067669173%\n",
      "Iteration: 500. Loss: 0.036906372755765915. Accuracy: 87.96992481203007%\n",
      "Iteration: 600. Loss: 0.1623665690422058. Accuracy: 85.33834586466165%\n",
      "Iteration: 700. Loss: 0.11921750009059906. Accuracy: 86.46616541353383%\n",
      "Iteration: 800. Loss: 0.006687048356980085. Accuracy: 87.59398496240601%\n",
      "Iteration: 900. Loss: 0.026652328670024872. Accuracy: 83.83458646616542%\n",
      "Iteration: 1000. Loss: 0.07855159044265747. Accuracy: 89.47368421052632%\n",
      "Iteration: 1100. Loss: 0.10982878506183624. Accuracy: 88.7218045112782%\n",
      "Iteration: 1200. Loss: 0.013553973287343979. Accuracy: 86.09022556390977%\n",
      "Iteration: 1300. Loss: 0.01495401468127966. Accuracy: 89.09774436090225%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1400. Loss: 0.0064970930106937885. Accuracy: 86.46616541353383%\n",
      "Iteration: 1500. Loss: 1.4212934970855713. Accuracy: 85.71428571428571%\n",
      "Iteration: 200. Loss: 0.7029555439949036. Accuracy: 87.96992481203007%\n",
      "Iteration: 300. Loss: 0.01260469015687704. Accuracy: 85.71428571428571%\n",
      "Iteration: 400. Loss: 0.023288190364837646. Accuracy: 87.96992481203007%\n",
      "Iteration: 500. Loss: 0.016081858426332474. Accuracy: 82.70676691729324%\n",
      "Iteration: 600. Loss: 0.0060133966617286205. Accuracy: 84.21052631578948%\n",
      "Iteration: 700. Loss: 0.0031439659651368856. Accuracy: 86.84210526315789%\n",
      "Iteration: 800. Loss: 0.0072953966446220875. Accuracy: 89.47368421052632%\n",
      "Iteration: 900. Loss: 1.3164324760437012. Accuracy: 87.21804511278195%\n",
      "Iteration: 1000. Loss: 0.020978815853595734. Accuracy: 77.06766917293233%\n",
      "Iteration: 1100. Loss: 0.003361648181453347. Accuracy: 86.46616541353383%\n",
      "Iteration: 1200. Loss: 0.005521285813301802. Accuracy: 88.34586466165413%\n",
      "Iteration: 1300. Loss: 1.5787038803100586. Accuracy: 66.9172932330827%\n",
      "Iteration: 1400. Loss: 1.3535346984863281. Accuracy: 80.45112781954887%\n",
      "Iteration: 1500. Loss: 0.007993139326572418. Accuracy: 87.21804511278195%\n",
      "Iteration: 1600. Loss: 0.00189779803622514. Accuracy: 86.84210526315789%\n",
      "Iteration: 1700. Loss: 0.01711808517575264. Accuracy: 87.59398496240601%\n",
      "Iteration: 1800. Loss: 0.003271111287176609. Accuracy: 84.9624060150376%\n",
      "Iteration: 1900. Loss: 0.003302360652014613. Accuracy: 86.09022556390977%\n",
      "EPOCH -- 7\n",
      "Iteration: 0. Loss: 0.0014429405564442277. Accuracy: 79.32330827067669%\n",
      "Iteration: 100. Loss: 0.007114197593182325. Accuracy: 85.33834586466165%\n",
      "Iteration: 200. Loss: 0.0015705404803156853. Accuracy: 85.33834586466165%\n",
      "Iteration: 300. Loss: 0.0022232832852751017. Accuracy: 88.34586466165413%\n",
      "Iteration: 400. Loss: 0.0044031813740730286. Accuracy: 79.32330827067669%\n",
      "Iteration: 500. Loss: 0.014625833369791508. Accuracy: 87.96992481203007%\n",
      "Iteration: 600. Loss: 0.005217269994318485. Accuracy: 87.21804511278195%\n",
      "Iteration: 700. Loss: 0.004078523721545935. Accuracy: 87.96992481203007%\n",
      "Iteration: 800. Loss: 0.006831740494817495. Accuracy: 86.84210526315789%\n",
      "Iteration: 900. Loss: 0.000988114275969565. Accuracy: 88.34586466165413%\n",
      "Iteration: 1000. Loss: 0.002011063741520047. Accuracy: 87.21804511278195%\n",
      "Iteration: 1100. Loss: 0.0013190149329602718. Accuracy: 82.70676691729324%\n",
      "Iteration: 1200. Loss: 0.01695319078862667. Accuracy: 86.09022556390977%\n",
      "Iteration: 1300. Loss: 0.003045446705073118. Accuracy: 85.33834586466165%\n",
      "Iteration: 1400. Loss: 0.004611927084624767. Accuracy: 86.09022556390977%\n",
      "Iteration: 1500. Loss: 0.0015628041001036763. Accuracy: 85.71428571428571%\n",
      "Iteration: 1600. Loss: 0.0055276877246797085. Accuracy: 74.43609022556392%\n",
      "Iteration: 1700. Loss: 0.0034191501326858997. Accuracy: 86.84210526315789%\n",
      "Iteration: 1800. Loss: 0.22235798835754395. Accuracy: 88.7218045112782%\n",
      "Iteration: 1900. Loss: 0.007212671916931868. Accuracy: 87.59398496240601%\n",
      "EPOCH -- 8\n",
      "Iteration: 0. Loss: 0.013022378087043762. Accuracy: 75.93984962406014%\n",
      "Iteration: 100. Loss: 0.005769504699856043. Accuracy: 86.46616541353383%\n",
      "Iteration: 200. Loss: 0.006616825703531504. Accuracy: 82.33082706766918%\n",
      "Iteration: 300. Loss: 0.023956825956702232. Accuracy: 86.46616541353383%\n",
      "Iteration: 400. Loss: 0.002051988383755088. Accuracy: 69.92481203007519%\n",
      "Iteration: 500. Loss: 0.004397603217512369. Accuracy: 87.59398496240601%\n",
      "Iteration: 600. Loss: 0.06992778182029724. Accuracy: 87.21804511278195%\n",
      "Iteration: 700. Loss: 0.42369696497917175. Accuracy: 87.59398496240601%\n",
      "Iteration: 800. Loss: 0.009806433692574501. Accuracy: 86.84210526315789%\n",
      "Iteration: 900. Loss: 0.007867656648159027. Accuracy: 87.21804511278195%\n",
      "Iteration: 1000. Loss: 0.002502050483599305. Accuracy: 86.84210526315789%\n",
      "Iteration: 1100. Loss: 0.03204968944191933. Accuracy: 89.09774436090225%\n",
      "Iteration: 1200. Loss: 0.0018825681181624532. Accuracy: 86.84210526315789%\n",
      "Iteration: 1300. Loss: 0.002057222882285714. Accuracy: 83.83458646616542%\n",
      "Iteration: 1400. Loss: 0.3282763659954071. Accuracy: 87.96992481203007%\n",
      "Iteration: 1500. Loss: 0.0019566931296139956. Accuracy: 84.58646616541354%\n",
      "Iteration: 1600. Loss: 0.06042657420039177. Accuracy: 86.46616541353383%\n",
      "Iteration: 1700. Loss: 0.04375557601451874. Accuracy: 86.09022556390977%\n",
      "Iteration: 1800. Loss: 1.3706669807434082. Accuracy: 52.63157894736842%\n",
      "Iteration: 1900. Loss: 0.38695213198661804. Accuracy: 51.50375939849624%\n",
      "EPOCH -- 9\n",
      "Iteration: 0. Loss: 0.5887378454208374. Accuracy: 53.00751879699248%\n",
      "Iteration: 100. Loss: 0.5780525803565979. Accuracy: 60.902255639097746%\n",
      "Iteration: 200. Loss: 0.816295862197876. Accuracy: 56.390977443609025%\n",
      "Iteration: 300. Loss: 0.49202650785446167. Accuracy: 53.38345864661654%\n",
      "Iteration: 400. Loss: 0.8219716548919678. Accuracy: 52.63157894736842%\n",
      "Iteration: 500. Loss: 0.5004971027374268. Accuracy: 55.6390977443609%\n",
      "Iteration: 600. Loss: 0.40279021859169006. Accuracy: 62.03007518796993%\n",
      "Iteration: 700. Loss: 0.016721215099096298. Accuracy: 62.78195488721804%\n",
      "Iteration: 800. Loss: 0.7174630165100098. Accuracy: 72.55639097744361%\n",
      "Iteration: 900. Loss: 0.013139214366674423. Accuracy: 84.58646616541354%\n",
      "Iteration: 1000. Loss: 0.004114852286875248. Accuracy: 86.84210526315789%\n",
      "Iteration: 1100. Loss: 0.0025414093397557735. Accuracy: 90.22556390977444%\n",
      "Iteration: 1200. Loss: 0.004892283584922552. Accuracy: 89.09774436090225%\n",
      "Iteration: 1300. Loss: 0.0027192779816687107. Accuracy: 89.09774436090225%\n",
      "Iteration: 1400. Loss: 2.9547348022460938. Accuracy: 59.3984962406015%\n",
      "Iteration: 1500. Loss: 0.025631634518504143. Accuracy: 84.58646616541354%\n",
      "Iteration: 1600. Loss: 0.003886884544044733. Accuracy: 86.46616541353383%\n",
      "Iteration: 1700. Loss: 0.015394669026136398. Accuracy: 87.59398496240601%\n",
      "Iteration: 1800. Loss: 0.0022890574764460325. Accuracy: 89.47368421052632%\n",
      "Iteration: 1900. Loss: 0.0018549631349742413. Accuracy: 88.7218045112782%\n",
      "EPOCH -- 10\n",
      "Iteration: 0. Loss: 0.07707443088293076. Accuracy: 77.81954887218045%\n",
      "Iteration: 100. Loss: 0.03479960188269615. Accuracy: 86.46616541353383%\n",
      "Iteration: 200. Loss: 0.005111245904117823. Accuracy: 88.34586466165413%\n",
      "Iteration: 300. Loss: 0.0036883200518786907. Accuracy: 90.6015037593985%\n",
      "Iteration: 400. Loss: 0.003996244631707668. Accuracy: 88.34586466165413%\n",
      "Iteration: 500. Loss: 0.01838628761470318. Accuracy: 79.69924812030075%\n",
      "Iteration: 600. Loss: 0.010347764007747173. Accuracy: 85.33834586466165%\n",
      "Iteration: 700. Loss: 0.01964411698281765. Accuracy: 85.33834586466165%\n",
      "Iteration: 800. Loss: 0.015507355332374573. Accuracy: 83.83458646616542%\n",
      "Iteration: 900. Loss: 0.01033785380423069. Accuracy: 86.09022556390977%\n",
      "Iteration: 1000. Loss: 0.004050979390740395. Accuracy: 84.9624060150376%\n",
      "Iteration: 1100. Loss: 0.005357787944376469. Accuracy: 88.34586466165413%\n",
      "Iteration: 1200. Loss: 0.06022399663925171. Accuracy: 87.59398496240601%\n",
      "Iteration: 1300. Loss: 0.0028880813624709845. Accuracy: 87.59398496240601%\n",
      "Iteration: 1400. Loss: 0.007007308769971132. Accuracy: 84.9624060150376%\n",
      "Iteration: 1500. Loss: 0.017828447744250298. Accuracy: 87.21804511278195%\n",
      "Iteration: 1600. Loss: 0.008608967065811157. Accuracy: 86.46616541353383%\n",
      "Iteration: 1700. Loss: 0.0043462105095386505. Accuracy: 86.46616541353383%\n",
      "Iteration: 1800. Loss: 0.007264863699674606. Accuracy: 81.95488721804512%\n",
      "Iteration: 1900. Loss: 0.00426181685179472. Accuracy: 84.58646616541354%\n",
      "EPOCH -- 11\n",
      "Iteration: 0. Loss: 0.00295048370026052. Accuracy: 87.96992481203007%\n",
      "Iteration: 100. Loss: 0.0020114206708967686. Accuracy: 86.09022556390977%\n",
      "Iteration: 200. Loss: 0.0025754161179065704. Accuracy: 83.0827067669173%\n",
      "Iteration: 300. Loss: 0.001793206320144236. Accuracy: 87.96992481203007%\n",
      "Iteration: 400. Loss: 0.001470794901251793. Accuracy: 86.46616541353383%\n",
      "Iteration: 500. Loss: 0.001302347518503666. Accuracy: 86.84210526315789%\n",
      "Iteration: 600. Loss: 0.0009112972766160965. Accuracy: 87.21804511278195%\n",
      "Iteration: 700. Loss: 0.0011753087164834142. Accuracy: 86.84210526315789%\n",
      "Iteration: 800. Loss: 0.0010750473011285067. Accuracy: 86.46616541353383%\n",
      "Iteration: 900. Loss: 1.60116708278656. Accuracy: 81.203007518797%\n",
      "Iteration: 1000. Loss: 0.018124088644981384. Accuracy: 88.7218045112782%\n",
      "Iteration: 1100. Loss: 0.002037355676293373. Accuracy: 87.96992481203007%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1200. Loss: 0.0014174662064760923. Accuracy: 87.21804511278195%\n",
      "Iteration: 1300. Loss: 0.001042894902639091. Accuracy: 86.46616541353383%\n",
      "Iteration: 1400. Loss: 0.0013633014168590307. Accuracy: 87.21804511278195%\n",
      "Iteration: 1500. Loss: 0.0016487350221723318. Accuracy: 90.6015037593985%\n",
      "Iteration: 1600. Loss: 0.0029856651090085506. Accuracy: 89.09774436090225%\n",
      "Iteration: 1700. Loss: 0.0025914679281413555. Accuracy: 89.47368421052632%\n",
      "Iteration: 1800. Loss: 0.0018995827995240688. Accuracy: 88.7218045112782%\n",
      "Iteration: 1900. Loss: 0.002393835224211216. Accuracy: 86.09022556390977%\n",
      "EPOCH -- 12\n",
      "Iteration: 0. Loss: 0.001536618685349822. Accuracy: 87.21804511278195%\n",
      "Iteration: 100. Loss: 0.0034092895220965147. Accuracy: 86.46616541353383%\n",
      "Iteration: 200. Loss: 0.0011102947173640132. Accuracy: 86.84210526315789%\n",
      "Iteration: 300. Loss: 0.005297551397234201. Accuracy: 80.45112781954887%\n",
      "Iteration: 400. Loss: 0.010045211762189865. Accuracy: 87.59398496240601%\n",
      "Iteration: 500. Loss: 0.0052198790945112705. Accuracy: 84.9624060150376%\n",
      "Iteration: 600. Loss: 0.005766660440713167. Accuracy: 88.7218045112782%\n",
      "Iteration: 700. Loss: 0.005083374213427305. Accuracy: 86.84210526315789%\n",
      "Iteration: 800. Loss: 0.010780192911624908. Accuracy: 86.84210526315789%\n",
      "Iteration: 900. Loss: 0.008573982864618301. Accuracy: 87.59398496240601%\n",
      "Iteration: 1000. Loss: 0.0016218378441408277. Accuracy: 86.09022556390977%\n",
      "Iteration: 1100. Loss: 0.01466565765440464. Accuracy: 87.59398496240601%\n",
      "Iteration: 1200. Loss: 0.0029609431512653828. Accuracy: 88.34586466165413%\n",
      "Iteration: 1300. Loss: 0.007879839278757572. Accuracy: 87.96992481203007%\n",
      "Iteration: 1400. Loss: 0.0019181440584361553. Accuracy: 88.7218045112782%\n",
      "Iteration: 1500. Loss: 0.0022595608606934547. Accuracy: 78.94736842105263%\n",
      "Iteration: 1600. Loss: 0.004613707307726145. Accuracy: 79.32330827067669%\n",
      "Iteration: 1700. Loss: 0.0313381552696228. Accuracy: 81.203007518797%\n",
      "Iteration: 1800. Loss: 1.3897669315338135. Accuracy: 65.78947368421052%\n",
      "Iteration: 1900. Loss: 0.04353133216500282. Accuracy: 87.96992481203007%\n",
      "EPOCH -- 13\n",
      "Iteration: 0. Loss: 0.014416465535759926. Accuracy: 90.22556390977444%\n",
      "Iteration: 100. Loss: 0.006277367472648621. Accuracy: 89.47368421052632%\n",
      "Iteration: 200. Loss: 0.002444852376356721. Accuracy: 86.84210526315789%\n",
      "Iteration: 300. Loss: 0.002427133498713374. Accuracy: 83.45864661654136%\n",
      "Iteration: 400. Loss: 0.05653071403503418. Accuracy: 90.22556390977444%\n",
      "Iteration: 500. Loss: 0.07751690596342087. Accuracy: 89.09774436090225%\n",
      "Iteration: 600. Loss: 1.4862704277038574. Accuracy: 86.09022556390977%\n",
      "Iteration: 700. Loss: 0.03304367512464523. Accuracy: 83.0827067669173%\n",
      "Iteration: 800. Loss: 0.002820563269779086. Accuracy: 87.96992481203007%\n",
      "Iteration: 900. Loss: 0.0037157556507736444. Accuracy: 85.71428571428571%\n",
      "Iteration: 1000. Loss: 0.0009858515113592148. Accuracy: 87.96992481203007%\n",
      "Iteration: 1100. Loss: 0.02005840837955475. Accuracy: 75.56390977443608%\n",
      "Iteration: 1200. Loss: 0.0019973821472376585. Accuracy: 83.0827067669173%\n",
      "Iteration: 1300. Loss: 0.006037806160748005. Accuracy: 87.59398496240601%\n",
      "Iteration: 1400. Loss: 0.0037712184712290764. Accuracy: 87.21804511278195%\n",
      "Iteration: 1500. Loss: 0.005731339566409588. Accuracy: 88.34586466165413%\n",
      "Iteration: 1600. Loss: 0.003834159579128027. Accuracy: 84.9624060150376%\n",
      "Iteration: 1700. Loss: 0.0021899782586842775. Accuracy: 88.7218045112782%\n",
      "Iteration: 1800. Loss: 0.0020611488725990057. Accuracy: 85.71428571428571%\n",
      "Iteration: 1900. Loss: 0.005847845692187548. Accuracy: 57.89473684210526%\n",
      "EPOCH -- 14\n",
      "Iteration: 0. Loss: 0.008330833166837692. Accuracy: 86.84210526315789%\n",
      "Iteration: 100. Loss: 0.005751844495534897. Accuracy: 86.84210526315789%\n",
      "Iteration: 200. Loss: 0.004109866451472044. Accuracy: 87.21804511278195%\n",
      "Iteration: 300. Loss: 0.2522857189178467. Accuracy: 87.59398496240601%\n",
      "Iteration: 400. Loss: 0.002637838013470173. Accuracy: 89.47368421052632%\n",
      "Iteration: 500. Loss: 0.0012401993153616786. Accuracy: 86.84210526315789%\n",
      "Iteration: 600. Loss: 0.002797977067530155. Accuracy: 87.59398496240601%\n",
      "Iteration: 700. Loss: 0.0014081810368224978. Accuracy: 87.59398496240601%\n",
      "Iteration: 800. Loss: 0.00442656222730875. Accuracy: 86.46616541353383%\n",
      "Iteration: 900. Loss: 0.046230997890233994. Accuracy: 87.96992481203007%\n",
      "Iteration: 1000. Loss: 0.0020026168785989285. Accuracy: 89.09774436090225%\n",
      "Iteration: 1100. Loss: 0.003604583442211151. Accuracy: 86.84210526315789%\n",
      "Iteration: 1200. Loss: 0.027530044317245483. Accuracy: 89.47368421052632%\n",
      "Iteration: 1300. Loss: 0.01605980470776558. Accuracy: 87.59398496240601%\n",
      "Iteration: 1400. Loss: 0.0009455977124162018. Accuracy: 86.84210526315789%\n",
      "Iteration: 1500. Loss: 0.0017526278970763087. Accuracy: 85.71428571428571%\n",
      "Iteration: 1600. Loss: 0.0016843193443492055. Accuracy: 85.33834586466165%\n",
      "Iteration: 1700. Loss: 0.007498097140341997. Accuracy: 87.21804511278195%\n",
      "Iteration: 1800. Loss: 0.001699671265669167. Accuracy: 81.95488721804512%\n",
      "Iteration: 1900. Loss: 0.0010676642414182425. Accuracy: 83.45864661654136%\n",
      "EPOCH -- 15\n",
      "Iteration: 0. Loss: 0.0010057396721094847. Accuracy: 84.21052631578948%\n",
      "Iteration: 100. Loss: 0.0014728185487911105. Accuracy: 84.9624060150376%\n",
      "Iteration: 200. Loss: 0.003914671018719673. Accuracy: 81.95488721804512%\n",
      "Iteration: 300. Loss: 0.019850876182317734. Accuracy: 86.09022556390977%\n",
      "Iteration: 400. Loss: 0.06063337251543999. Accuracy: 88.34586466165413%\n",
      "Iteration: 500. Loss: 0.0012953233672305942. Accuracy: 87.21804511278195%\n",
      "Iteration: 600. Loss: 0.0007856381707824767. Accuracy: 89.09774436090225%\n",
      "Iteration: 700. Loss: 0.000886285852175206. Accuracy: 87.21804511278195%\n",
      "Iteration: 800. Loss: 0.000708090839907527. Accuracy: 87.21804511278195%\n",
      "Iteration: 900. Loss: 0.0005298641044646502. Accuracy: 89.84962406015038%\n",
      "Iteration: 1000. Loss: 0.0007583603146485984. Accuracy: 88.7218045112782%\n",
      "Iteration: 1100. Loss: 0.0008737798780202866. Accuracy: 86.84210526315789%\n",
      "Iteration: 1200. Loss: 0.00019631843315437436. Accuracy: 86.84210526315789%\n",
      "Iteration: 1300. Loss: 0.00043585337698459625. Accuracy: 88.7218045112782%\n",
      "Iteration: 1400. Loss: 0.0014028241857886314. Accuracy: 88.7218045112782%\n",
      "Iteration: 1500. Loss: 0.0009105826611630619. Accuracy: 87.59398496240601%\n",
      "Iteration: 1600. Loss: 0.000529149197973311. Accuracy: 89.09774436090225%\n",
      "Iteration: 1700. Loss: 0.0006053998949937522. Accuracy: 87.59398496240601%\n",
      "Iteration: 1800. Loss: 0.0015328098088502884. Accuracy: 88.7218045112782%\n",
      "Iteration: 1900. Loss: 0.0003711488388944417. Accuracy: 87.21804511278195%\n",
      "EPOCH -- 16\n",
      "Iteration: 0. Loss: 0.0014194899704307318. Accuracy: 87.96992481203007%\n",
      "Iteration: 100. Loss: 0.00048232366680167615. Accuracy: 87.59398496240601%\n",
      "Iteration: 200. Loss: 0.000647692708298564. Accuracy: 87.96992481203007%\n",
      "Iteration: 300. Loss: 0.0004209585895296186. Accuracy: 87.21804511278195%\n",
      "Iteration: 400. Loss: 0.0003325386205688119. Accuracy: 86.84210526315789%\n",
      "Iteration: 500. Loss: 0.0020679295994341373. Accuracy: 88.34586466165413%\n",
      "Iteration: 600. Loss: 0.06794264167547226. Accuracy: 87.21804511278195%\n",
      "Iteration: 700. Loss: 0.0027635025326162577. Accuracy: 88.7218045112782%\n",
      "Iteration: 800. Loss: 0.03457564488053322. Accuracy: 79.69924812030075%\n",
      "Iteration: 900. Loss: 0.006216001696884632. Accuracy: 84.9624060150376%\n",
      "Iteration: 1000. Loss: 0.017442520707845688. Accuracy: 80.45112781954887%\n",
      "Iteration: 1100. Loss: 0.0030680273193866014. Accuracy: 88.7218045112782%\n",
      "Iteration: 1200. Loss: 0.003732383018359542. Accuracy: 86.46616541353383%\n",
      "Iteration: 1300. Loss: 0.0015125750796869397. Accuracy: 84.9624060150376%\n",
      "Iteration: 1400. Loss: 0.004367337562143803. Accuracy: 86.09022556390977%\n",
      "Iteration: 1500. Loss: 0.0012230543652549386. Accuracy: 87.59398496240601%\n",
      "Iteration: 1600. Loss: 0.0008667526417411864. Accuracy: 87.21804511278195%\n",
      "Iteration: 1700. Loss: 0.0009658439084887505. Accuracy: 86.84210526315789%\n",
      "Iteration: 1800. Loss: 0.0015217402251437306. Accuracy: 84.21052631578948%\n",
      "Iteration: 1900. Loss: 0.002348286332562566. Accuracy: 87.96992481203007%\n",
      "EPOCH -- 17\n",
      "Iteration: 0. Loss: 0.047263529151678085. Accuracy: 87.21804511278195%\n",
      "Iteration: 100. Loss: 0.0014080620603635907. Accuracy: 87.21804511278195%\n",
      "Iteration: 200. Loss: 0.0012831796193495393. Accuracy: 86.84210526315789%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 300. Loss: 0.0006800960982218385. Accuracy: 88.7218045112782%\n",
      "Iteration: 400. Loss: 0.0029420447535812855. Accuracy: 88.7218045112782%\n",
      "Iteration: 500. Loss: 0.0036427113227546215. Accuracy: 87.59398496240601%\n",
      "Iteration: 600. Loss: 0.0026144154835492373. Accuracy: 68.04511278195488%\n",
      "Iteration: 700. Loss: 0.0034623933024704456. Accuracy: 87.96992481203007%\n",
      "Iteration: 800. Loss: 0.004420509096235037. Accuracy: 89.47368421052632%\n",
      "Iteration: 900. Loss: 0.5754057765007019. Accuracy: 90.22556390977444%\n",
      "Iteration: 1000. Loss: 0.08577845990657806. Accuracy: 88.34586466165413%\n",
      "Iteration: 1100. Loss: 0.0018199799815192819. Accuracy: 89.09774436090225%\n",
      "Iteration: 1200. Loss: 0.005014343652874231. Accuracy: 88.7218045112782%\n",
      "Iteration: 1300. Loss: 0.00646381126716733. Accuracy: 89.47368421052632%\n",
      "Iteration: 1400. Loss: 0.013326265849173069. Accuracy: 87.21804511278195%\n",
      "Iteration: 1500. Loss: 0.0014467497821897268. Accuracy: 86.09022556390977%\n",
      "Iteration: 1600. Loss: 5.802181720733643. Accuracy: 64.66165413533835%\n",
      "Iteration: 1700. Loss: 0.005555191542953253. Accuracy: 83.83458646616542%\n",
      "Iteration: 1800. Loss: 0.0029740172903984785. Accuracy: 85.33834586466165%\n",
      "Iteration: 1900. Loss: 0.11419577151536942. Accuracy: 86.84210526315789%\n",
      "EPOCH -- 18\n",
      "Iteration: 0. Loss: 0.0017999890260398388. Accuracy: 85.33834586466165%\n",
      "Iteration: 100. Loss: 0.0014180614380165935. Accuracy: 82.70676691729324%\n",
      "Iteration: 200. Loss: 0.01262941025197506. Accuracy: 86.46616541353383%\n",
      "Iteration: 300. Loss: 0.001035987981595099. Accuracy: 83.83458646616542%\n",
      "Iteration: 400. Loss: 0.001105293515138328. Accuracy: 81.95488721804512%\n",
      "Iteration: 500. Loss: 0.000715833914000541. Accuracy: 86.09022556390977%\n",
      "Iteration: 600. Loss: 0.0025760105345398188. Accuracy: 83.0827067669173%\n",
      "Iteration: 700. Loss: 0.010027745738625526. Accuracy: 80.07518796992481%\n",
      "Iteration: 800. Loss: 0.7549779415130615. Accuracy: 74.43609022556392%\n",
      "Iteration: 900. Loss: 0.0023864619433879852. Accuracy: 87.21804511278195%\n",
      "Iteration: 1000. Loss: 0.1449747532606125. Accuracy: 83.83458646616542%\n",
      "Iteration: 1100. Loss: 0.0057354881428182125. Accuracy: 85.33834586466165%\n",
      "Iteration: 1200. Loss: 0.00674246484413743. Accuracy: 86.46616541353383%\n",
      "Iteration: 1300. Loss: 0.33239683508872986. Accuracy: 45.86466165413534%\n",
      "Iteration: 1400. Loss: 0.438683420419693. Accuracy: 54.88721804511278%\n",
      "Iteration: 1500. Loss: 1.058984637260437. Accuracy: 51.12781954887218%\n",
      "Iteration: 1600. Loss: 0.8025302290916443. Accuracy: 54.88721804511278%\n",
      "Iteration: 1700. Loss: 0.9642775058746338. Accuracy: 56.015037593984964%\n",
      "Iteration: 1800. Loss: 0.5613356232643127. Accuracy: 56.390977443609025%\n",
      "Iteration: 1900. Loss: 0.4228596091270447. Accuracy: 57.5187969924812%\n",
      "EPOCH -- 19\n",
      "Iteration: 0. Loss: 0.7689749002456665. Accuracy: 50.75187969924812%\n",
      "Iteration: 100. Loss: 0.6447705626487732. Accuracy: 49.62406015037594%\n",
      "Iteration: 200. Loss: 0.5881936550140381. Accuracy: 58.64661654135338%\n",
      "Iteration: 300. Loss: 0.8766226768493652. Accuracy: 58.64661654135338%\n",
      "Iteration: 400. Loss: 1.1486990451812744. Accuracy: 57.5187969924812%\n",
      "Iteration: 500. Loss: 0.04161014407873154. Accuracy: 54.51127819548872%\n",
      "Iteration: 600. Loss: 0.4965362548828125. Accuracy: 58.64661654135338%\n",
      "Iteration: 700. Loss: 0.4637288451194763. Accuracy: 58.27067669172932%\n",
      "Iteration: 800. Loss: 0.41071850061416626. Accuracy: 57.142857142857146%\n",
      "Iteration: 900. Loss: 0.7393730878829956. Accuracy: 49.24812030075188%\n",
      "Iteration: 1000. Loss: 0.02238529361784458. Accuracy: 69.92481203007519%\n",
      "Iteration: 1100. Loss: 1.3950477838516235. Accuracy: 67.29323308270676%\n",
      "Iteration: 1200. Loss: 0.20438618957996368. Accuracy: 65.0375939849624%\n",
      "Iteration: 1300. Loss: 0.01063571684062481. Accuracy: 70.30075187969925%\n",
      "Iteration: 1400. Loss: 0.4427482783794403. Accuracy: 68.796992481203%\n",
      "Iteration: 1500. Loss: 0.20210079848766327. Accuracy: 68.42105263157895%\n",
      "Iteration: 1600. Loss: 0.9214262962341309. Accuracy: 68.796992481203%\n",
      "Iteration: 1700. Loss: 0.008569727651774883. Accuracy: 68.42105263157895%\n",
      "Iteration: 1800. Loss: 0.0054669869132339954. Accuracy: 67.66917293233082%\n",
      "Iteration: 1900. Loss: 1.296217441558838. Accuracy: 68.04511278195488%\n",
      "EPOCH -- 20\n",
      "Iteration: 0. Loss: 0.5928691029548645. Accuracy: 68.04511278195488%\n",
      "Iteration: 100. Loss: 1.3098359107971191. Accuracy: 68.04511278195488%\n",
      "Iteration: 200. Loss: 0.007683604024350643. Accuracy: 68.796992481203%\n",
      "Iteration: 300. Loss: 0.18021434545516968. Accuracy: 67.66917293233082%\n",
      "Iteration: 400. Loss: 1.4783334732055664. Accuracy: 68.796992481203%\n",
      "Iteration: 500. Loss: 0.29411324858665466. Accuracy: 69.92481203007519%\n",
      "Iteration: 600. Loss: 0.0029277815483510494. Accuracy: 68.42105263157895%\n",
      "Iteration: 700. Loss: 0.21974653005599976. Accuracy: 67.66917293233082%\n",
      "Iteration: 800. Loss: 1.2494356632232666. Accuracy: 69.54887218045113%\n",
      "Iteration: 900. Loss: 0.0036953275557607412. Accuracy: 71.80451127819549%\n",
      "Iteration: 1000. Loss: 0.19085533916950226. Accuracy: 71.05263157894737%\n",
      "Iteration: 1100. Loss: 0.12990601360797882. Accuracy: 71.42857142857143%\n",
      "Iteration: 1200. Loss: 0.9731667041778564. Accuracy: 72.55639097744361%\n",
      "Iteration: 1300. Loss: 0.0020811345893889666. Accuracy: 72.18045112781955%\n",
      "Iteration: 1400. Loss: 0.38175079226493835. Accuracy: 69.92481203007519%\n",
      "Iteration: 1500. Loss: 0.0019527667900547385. Accuracy: 72.18045112781955%\n",
      "Iteration: 1600. Loss: 0.09899801015853882. Accuracy: 71.80451127819549%\n",
      "Iteration: 1700. Loss: 0.0022261380217969418. Accuracy: 72.55639097744361%\n",
      "Iteration: 1800. Loss: 0.1948375105857849. Accuracy: 72.55639097744361%\n",
      "Iteration: 1900. Loss: 0.0014324652729555964. Accuracy: 72.55639097744361%\n",
      "EPOCH -- 21\n",
      "Iteration: 0. Loss: 0.0017389428103342652. Accuracy: 72.18045112781955%\n",
      "Iteration: 100. Loss: 0.002836135681718588. Accuracy: 71.42857142857143%\n",
      "Iteration: 200. Loss: 0.19902586936950684. Accuracy: 81.203007518797%\n",
      "Iteration: 300. Loss: 0.001134705264121294. Accuracy: 79.69924812030075%\n",
      "Iteration: 400. Loss: 0.0010525407269597054. Accuracy: 80.82706766917293%\n",
      "Iteration: 500. Loss: 0.04397840052843094. Accuracy: 82.70676691729324%\n",
      "Iteration: 600. Loss: 0.023766864091157913. Accuracy: 82.33082706766918%\n",
      "Iteration: 700. Loss: 0.06264481693506241. Accuracy: 82.70676691729324%\n",
      "Iteration: 800. Loss: 0.07782552391290665. Accuracy: 81.57894736842105%\n",
      "Iteration: 900. Loss: 0.0592958889901638. Accuracy: 80.07518796992481%\n",
      "Iteration: 1000. Loss: 0.05076579004526138. Accuracy: 80.45112781954887%\n",
      "Iteration: 1100. Loss: 0.0007789676310494542. Accuracy: 81.57894736842105%\n",
      "Iteration: 1200. Loss: 0.03152495250105858. Accuracy: 79.69924812030075%\n",
      "Iteration: 1300. Loss: 0.06454818695783615. Accuracy: 82.70676691729324%\n",
      "Iteration: 1400. Loss: 0.0005888396990485489. Accuracy: 81.203007518797%\n",
      "Iteration: 1500. Loss: 0.0005272428970783949. Accuracy: 83.45864661654136%\n",
      "Iteration: 1600. Loss: 0.0009112972766160965. Accuracy: 82.33082706766918%\n",
      "Iteration: 1700. Loss: 0.05655403062701225. Accuracy: 83.45864661654136%\n",
      "Iteration: 1800. Loss: 0.0005423743859864771. Accuracy: 83.83458646616542%\n",
      "Iteration: 1900. Loss: 2.8658924102783203. Accuracy: 81.95488721804512%\n",
      "EPOCH -- 22\n",
      "Iteration: 0. Loss: 0.14147654175758362. Accuracy: 81.57894736842105%\n",
      "Iteration: 100. Loss: 0.05144801735877991. Accuracy: 80.45112781954887%\n",
      "Iteration: 200. Loss: 0.0006126672378741205. Accuracy: 81.95488721804512%\n",
      "Iteration: 300. Loss: 0.0014429405564442277. Accuracy: 80.82706766917293%\n",
      "Iteration: 400. Loss: 0.09067720174789429. Accuracy: 80.82706766917293%\n",
      "Iteration: 500. Loss: 0.0009545299108140171. Accuracy: 78.94736842105263%\n",
      "Iteration: 600. Loss: 0.000959412835072726. Accuracy: 80.45112781954887%\n",
      "Iteration: 700. Loss: 0.0006379238329827785. Accuracy: 80.07518796992481%\n",
      "Iteration: 800. Loss: 0.0008164886385202408. Accuracy: 81.57894736842105%\n",
      "Iteration: 900. Loss: 0.04798700660467148. Accuracy: 78.19548872180451%\n",
      "Iteration: 1000. Loss: 0.0006998711614869535. Accuracy: 82.33082706766918%\n",
      "Iteration: 1100. Loss: 0.0009913297835737467. Accuracy: 79.32330827067669%\n",
      "Iteration: 1200. Loss: 0.08522852510213852. Accuracy: 80.45112781954887%\n",
      "Iteration: 1300. Loss: 0.033570729196071625. Accuracy: 79.69924812030075%\n",
      "Iteration: 1400. Loss: 0.09221931546926498. Accuracy: 81.203007518797%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1500. Loss: 0.0006669919239357114. Accuracy: 81.57894736842105%\n",
      "Iteration: 1600. Loss: 0.20719191431999207. Accuracy: 80.45112781954887%\n",
      "Iteration: 1700. Loss: 0.0006990373367443681. Accuracy: 81.57894736842105%\n",
      "Iteration: 1800. Loss: 0.03556769713759422. Accuracy: 79.69924812030075%\n",
      "Iteration: 1900. Loss: 0.04713219031691551. Accuracy: 80.82706766917293%\n",
      "EPOCH -- 23\n",
      "Iteration: 0. Loss: 0.055448729544878006. Accuracy: 80.82706766917293%\n",
      "Iteration: 100. Loss: 0.0002824861148837954. Accuracy: 81.95488721804512%\n",
      "Iteration: 200. Loss: 0.049611642956733704. Accuracy: 79.69924812030075%\n",
      "Iteration: 300. Loss: 0.04654180258512497. Accuracy: 79.32330827067669%\n",
      "Iteration: 400. Loss: 0.07550942897796631. Accuracy: 79.69924812030075%\n",
      "Iteration: 500. Loss: 0.07230474054813385. Accuracy: 80.07518796992481%\n",
      "Iteration: 600. Loss: 0.9977675676345825. Accuracy: 52.255639097744364%\n",
      "Iteration: 700. Loss: 0.46485599875450134. Accuracy: 74.06015037593986%\n",
      "Iteration: 800. Loss: 1.512055516242981. Accuracy: 77.06766917293233%\n",
      "Iteration: 900. Loss: 0.06161258742213249. Accuracy: 84.21052631578948%\n",
      "Iteration: 1000. Loss: 0.025627799332141876. Accuracy: 83.45864661654136%\n",
      "Iteration: 1100. Loss: 0.05104222521185875. Accuracy: 83.0827067669173%\n",
      "Iteration: 1200. Loss: 0.09464262425899506. Accuracy: 82.70676691729324%\n",
      "Iteration: 1300. Loss: 0.07090926915407181. Accuracy: 81.95488721804512%\n",
      "Iteration: 1400. Loss: 0.07806481420993805. Accuracy: 82.70676691729324%\n",
      "Iteration: 1500. Loss: 0.008532378822565079. Accuracy: 82.33082706766918%\n",
      "Iteration: 1600. Loss: 2.0634939670562744. Accuracy: 34.962406015037594%\n",
      "Iteration: 1700. Loss: 0.37687450647354126. Accuracy: 80.45112781954887%\n",
      "Iteration: 1800. Loss: 0.06080681458115578. Accuracy: 81.95488721804512%\n",
      "Iteration: 1900. Loss: 0.23999711871147156. Accuracy: 83.0827067669173%\n",
      "EPOCH -- 24\n",
      "Iteration: 0. Loss: 0.07358452677726746. Accuracy: 79.32330827067669%\n",
      "Iteration: 100. Loss: 0.00504648732021451. Accuracy: 85.71428571428571%\n",
      "Iteration: 200. Loss: 0.002961894031614065. Accuracy: 84.9624060150376%\n",
      "Iteration: 300. Loss: 0.0013771107187494636. Accuracy: 84.58646616541354%\n",
      "Iteration: 400. Loss: 0.0054296404123306274. Accuracy: 80.82706766917293%\n",
      "Iteration: 500. Loss: 0.0012204349040985107. Accuracy: 85.33834586466165%\n",
      "Iteration: 600. Loss: 0.02700536511838436. Accuracy: 84.58646616541354%\n",
      "Iteration: 700. Loss: 0.0007764662150293589. Accuracy: 85.71428571428571%\n",
      "Iteration: 800. Loss: 0.0014919828390702605. Accuracy: 84.9624060150376%\n",
      "Iteration: 900. Loss: 1.1662554740905762. Accuracy: 82.70676691729324%\n",
      "Iteration: 1000. Loss: 0.0013944911770522594. Accuracy: 81.95488721804512%\n",
      "Iteration: 1100. Loss: 0.004234752152115107. Accuracy: 81.203007518797%\n",
      "Iteration: 1200. Loss: 0.011464312672615051. Accuracy: 84.21052631578948%\n",
      "Iteration: 1300. Loss: 0.0013558013597503304. Accuracy: 84.21052631578948%\n",
      "Iteration: 1400. Loss: 0.006149419117718935. Accuracy: 84.58646616541354%\n",
      "Iteration: 1500. Loss: 0.002639383776113391. Accuracy: 85.71428571428571%\n",
      "Iteration: 1600. Loss: 0.04550909623503685. Accuracy: 83.83458646616542%\n",
      "Iteration: 1700. Loss: 0.0010488491971045732. Accuracy: 84.9624060150376%\n",
      "Iteration: 1800. Loss: 0.015270582400262356. Accuracy: 83.0827067669173%\n",
      "Iteration: 1900. Loss: 0.0009575072908774018. Accuracy: 83.83458646616542%\n",
      "EPOCH -- 25\n",
      "Iteration: 0. Loss: 0.009188508614897728. Accuracy: 84.9624060150376%\n",
      "Iteration: 100. Loss: 0.0008952185744419694. Accuracy: 81.57894736842105%\n",
      "Iteration: 200. Loss: 0.018124792724847794. Accuracy: 83.83458646616542%\n",
      "Iteration: 300. Loss: 0.03817257657647133. Accuracy: 83.83458646616542%\n",
      "Iteration: 400. Loss: 0.02050604671239853. Accuracy: 81.57894736842105%\n",
      "Iteration: 500. Loss: 0.0004159538948442787. Accuracy: 85.33834586466165%\n",
      "Iteration: 600. Loss: 0.0007614573696628213. Accuracy: 83.45864661654136%\n",
      "Iteration: 700. Loss: 0.008822744712233543. Accuracy: 84.58646616541354%\n",
      "Iteration: 800. Loss: 0.0009684640099294484. Accuracy: 84.21052631578948%\n",
      "Iteration: 900. Loss: 0.000606710382271558. Accuracy: 84.58646616541354%\n",
      "Iteration: 1000. Loss: 0.0052790530025959015. Accuracy: 83.45864661654136%\n",
      "Iteration: 1100. Loss: 0.0006551980040967464. Accuracy: 84.21052631578948%\n",
      "Iteration: 1200. Loss: 0.0027997603174299. Accuracy: 84.58646616541354%\n",
      "Iteration: 1300. Loss: 0.0013383012264966965. Accuracy: 84.9624060150376%\n",
      "Iteration: 1400. Loss: 0.0013703251024708152. Accuracy: 85.33834586466165%\n",
      "Iteration: 1500. Loss: 0.0011700696777552366. Accuracy: 82.70676691729324%\n",
      "Iteration: 1600. Loss: 0.009663823992013931. Accuracy: 83.0827067669173%\n",
      "Iteration: 1700. Loss: 0.0014263942139223218. Accuracy: 84.9624060150376%\n",
      "Iteration: 1800. Loss: 0.0031721293926239014. Accuracy: 85.71428571428571%\n",
      "Iteration: 1900. Loss: 0.001749057904817164. Accuracy: 83.83458646616542%\n",
      "EPOCH -- 26\n",
      "Iteration: 0. Loss: 0.0009943069890141487. Accuracy: 83.45864661654136%\n",
      "Iteration: 100. Loss: 0.0007900454220362008. Accuracy: 84.21052631578948%\n",
      "Iteration: 200. Loss: 0.0004922132357023656. Accuracy: 83.45864661654136%\n",
      "Iteration: 300. Loss: 0.0008738989708945155. Accuracy: 83.45864661654136%\n",
      "Iteration: 400. Loss: 0.0008166077313944697. Accuracy: 84.21052631578948%\n",
      "Iteration: 500. Loss: 0.016144264489412308. Accuracy: 83.83458646616542%\n",
      "Iteration: 600. Loss: 0.026364773511886597. Accuracy: 81.57894736842105%\n",
      "Iteration: 700. Loss: 0.00749999051913619. Accuracy: 81.95488721804512%\n",
      "Iteration: 800. Loss: 0.0036055336240679026. Accuracy: 84.58646616541354%\n",
      "Iteration: 900. Loss: 0.003167257411405444. Accuracy: 83.83458646616542%\n",
      "Iteration: 1000. Loss: 0.0009807306341826916. Accuracy: 83.0827067669173%\n",
      "Iteration: 1100. Loss: 0.01177762821316719. Accuracy: 83.45864661654136%\n",
      "Iteration: 1200. Loss: 0.0006767605082131922. Accuracy: 83.83458646616542%\n",
      "Iteration: 1300. Loss: 0.0009274948388338089. Accuracy: 82.33082706766918%\n",
      "Iteration: 1400. Loss: 0.000962151971179992. Accuracy: 79.69924812030075%\n",
      "Iteration: 1500. Loss: 0.005119310691952705. Accuracy: 84.21052631578948%\n",
      "Iteration: 1600. Loss: 0.007580916862934828. Accuracy: 83.83458646616542%\n",
      "Iteration: 1700. Loss: 0.0037619550712406635. Accuracy: 84.9624060150376%\n",
      "Iteration: 1800. Loss: 0.0006459057331085205. Accuracy: 83.83458646616542%\n",
      "Iteration: 1900. Loss: 0.0068375421687960625. Accuracy: 84.9624060150376%\n",
      "EPOCH -- 27\n",
      "Iteration: 0. Loss: 0.008251740597188473. Accuracy: 83.83458646616542%\n",
      "Iteration: 100. Loss: 0.061671990901231766. Accuracy: 86.46616541353383%\n",
      "Iteration: 200. Loss: 0.0004781533498317003. Accuracy: 86.09022556390977%\n",
      "Iteration: 300. Loss: 0.0008105330052785575. Accuracy: 83.0827067669173%\n",
      "Iteration: 400. Loss: 0.0141721460968256. Accuracy: 83.45864661654136%\n",
      "Iteration: 500. Loss: 0.011336908675730228. Accuracy: 80.82706766917293%\n",
      "Iteration: 600. Loss: 0.0005775213940069079. Accuracy: 82.70676691729324%\n",
      "Iteration: 700. Loss: 0.0007427555974572897. Accuracy: 81.57894736842105%\n",
      "Iteration: 800. Loss: 0.014136534184217453. Accuracy: 85.71428571428571%\n",
      "Iteration: 900. Loss: 0.0006025406182743609. Accuracy: 84.9624060150376%\n",
      "Iteration: 1000. Loss: 0.003834397066384554. Accuracy: 84.58646616541354%\n",
      "Iteration: 1100. Loss: 0.007800237741321325. Accuracy: 85.71428571428571%\n",
      "Iteration: 1200. Loss: 0.000745018885936588. Accuracy: 85.33834586466165%\n",
      "Iteration: 1300. Loss: 0.0006637753685936332. Accuracy: 84.58646616541354%\n",
      "Iteration: 1400. Loss: 0.0006002769805490971. Accuracy: 86.46616541353383%\n",
      "Iteration: 1500. Loss: 0.0040668887086212635. Accuracy: 86.09022556390977%\n",
      "Iteration: 1600. Loss: 0.005476946011185646. Accuracy: 82.33082706766918%\n",
      "Iteration: 1700. Loss: 0.001623980118893087. Accuracy: 84.21052631578948%\n",
      "Iteration: 1800. Loss: 0.07817859202623367. Accuracy: 83.0827067669173%\n",
      "Iteration: 1900. Loss: 0.0023211699444800615. Accuracy: 84.9624060150376%\n",
      "EPOCH -- 28\n",
      "Iteration: 0. Loss: 0.0013190149329602718. Accuracy: 83.45864661654136%\n",
      "Iteration: 100. Loss: 0.012080362997949123. Accuracy: 81.203007518797%\n",
      "Iteration: 200. Loss: 0.001166259404271841. Accuracy: 81.203007518797%\n",
      "Iteration: 300. Loss: 0.004068906884640455. Accuracy: 80.45112781954887%\n",
      "Iteration: 400. Loss: 0.0021752286702394485. Accuracy: 81.95488721804512%\n",
      "Iteration: 500. Loss: 0.0023079682141542435. Accuracy: 83.0827067669173%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 600. Loss: 0.0015650654677301645. Accuracy: 84.9624060150376%\n",
      "Iteration: 700. Loss: 0.001279369811527431. Accuracy: 84.21052631578948%\n",
      "Iteration: 800. Loss: 0.010949527844786644. Accuracy: 84.21052631578948%\n",
      "Iteration: 900. Loss: 0.001276512397453189. Accuracy: 84.21052631578948%\n",
      "Iteration: 1000. Loss: 0.0006652049487456679. Accuracy: 81.95488721804512%\n",
      "Iteration: 1100. Loss: 0.0010040724882856011. Accuracy: 86.46616541353383%\n",
      "Iteration: 1200. Loss: 0.0011632826644927263. Accuracy: 81.95488721804512%\n",
      "Iteration: 1300. Loss: 0.0006046851049177349. Accuracy: 81.57894736842105%\n",
      "Iteration: 1400. Loss: 0.0006491222884505987. Accuracy: 81.57894736842105%\n",
      "Iteration: 1500. Loss: 0.002354946220293641. Accuracy: 82.33082706766918%\n",
      "Iteration: 1600. Loss: 0.0029948167502880096. Accuracy: 85.71428571428571%\n",
      "Iteration: 1700. Loss: 0.0008821171941235662. Accuracy: 82.70676691729324%\n",
      "Iteration: 1800. Loss: 0.033363908529281616. Accuracy: 74.43609022556392%\n",
      "Iteration: 1900. Loss: 0.020960604771971703. Accuracy: 84.9624060150376%\n",
      "EPOCH -- 29\n",
      "Iteration: 0. Loss: 0.015802627429366112. Accuracy: 84.58646616541354%\n",
      "Iteration: 100. Loss: 0.006680772174149752. Accuracy: 82.70676691729324%\n",
      "Iteration: 200. Loss: 0.0007447806419804692. Accuracy: 82.70676691729324%\n",
      "Iteration: 300. Loss: 0.011926179751753807. Accuracy: 83.45864661654136%\n",
      "Iteration: 400. Loss: 0.0008390005677938461. Accuracy: 82.70676691729324%\n",
      "Iteration: 500. Loss: 0.007575829979032278. Accuracy: 83.0827067669173%\n",
      "Iteration: 600. Loss: 0.0011629253858700395. Accuracy: 83.83458646616542%\n",
      "Iteration: 700. Loss: 0.0005694198189303279. Accuracy: 84.58646616541354%\n",
      "Iteration: 800. Loss: 0.0004602803383022547. Accuracy: 84.9624060150376%\n",
      "Iteration: 900. Loss: 0.00035577642847783864. Accuracy: 81.95488721804512%\n",
      "Iteration: 1000. Loss: 0.007381073199212551. Accuracy: 84.21052631578948%\n",
      "Iteration: 1100. Loss: 0.006208301056176424. Accuracy: 83.45864661654136%\n",
      "Iteration: 1200. Loss: 0.004528505261987448. Accuracy: 83.0827067669173%\n",
      "Iteration: 1300. Loss: 0.2094995677471161. Accuracy: 84.21052631578948%\n",
      "Iteration: 1400. Loss: 0.001158162602223456. Accuracy: 85.33834586466165%\n",
      "Iteration: 1500. Loss: 0.0012224590172991157. Accuracy: 82.70676691729324%\n",
      "Iteration: 1600. Loss: 0.002996480790898204. Accuracy: 85.33834586466165%\n",
      "Iteration: 1700. Loss: 0.002400257159024477. Accuracy: 84.21052631578948%\n",
      "Iteration: 1800. Loss: 0.0007805161876603961. Accuracy: 85.33834586466165%\n",
      "Iteration: 1900. Loss: 0.0016051754355430603. Accuracy: 85.71428571428571%\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 30\n",
    "model = model.train()\n",
    "for epoch in tqdm_notebook(range(max_epochs)):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (sent, label) in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        sent = sent.squeeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "          sent = sent.cuda()\n",
    "          label = label.cuda()\n",
    "        output = model.forward(sent)[0]\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for sent, label in testing_loader:\n",
    "                sent = sent.squeeze(0)\n",
    "                if torch.cuda.is_available():\n",
    "                  sent = sent.cuda()\n",
    "                  label = label.cuda()\n",
    "                output = model.forward(sent)[0]\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "422d280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "lst_prediction =[]\n",
    "lst_test = list(df_valid['text'])\n",
    "model.eval()\n",
    "for msg in lst_test:\n",
    "    input_msg, _ = prepare_features(msg)\n",
    "    if torch.cuda.is_available():\n",
    "        input_msg = input_msg.cuda()\n",
    "        output = model(input_msg)[0]\n",
    "        outputs.append(output)\n",
    "        _, pred_label = torch.max(output.data, 1)\n",
    "        prediction=list(label_to_inx.keys())[pred_label]\n",
    "        lst_prediction.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1eb97a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [o.to('cpu').detach().numpy().copy() for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3acaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "157ed40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_class = ['unsustainable','sustainable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "638fd11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2 = [] \n",
    "[predictions2.append([x[1] for x in [sorted(zip(example[0], lst_class), reverse=True)][0]]) for example in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d32c11f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a9e7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = [a[0] for a in predictions2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b0aecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_true = list(df_valid['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46901218",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, f1_micro, f1_macro = get_result(predictions3, lst_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6324c451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8533834586466166, 0.8533834586466166, 0.8518571408171134)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, f1_micro, f1_macro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc26bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
