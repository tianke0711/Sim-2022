{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9b64c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "from tqdm import tqdm_notebook\n",
    "from uuid import uuid4\n",
    "import tqdm\n",
    "\n",
    "## Torch Modules\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "from transformers import RobertaForSequenceClassification, RobertaConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "50ab6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(seq_1, max_seq_length = 140, zero_pad = True, include_CLS_token = True, include_SEP_token = True):\n",
    "    ## Tokenzine Input\n",
    "    \n",
    "    tokens_a = tokenizer.tokenize(seq_1)\n",
    "\n",
    "    ## Truncate\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "    ## Initialize Tokens\n",
    "    tokens = []\n",
    "    if include_CLS_token:\n",
    "        tokens.append(tokenizer.cls_token)\n",
    "    ## Add Tokens and separators\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "\n",
    "    if include_SEP_token:\n",
    "        tokens.append(tokenizer.sep_token)\n",
    "    \n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    ## Input Mask \n",
    "    input_mask = [1] * len(input_ids)\n",
    "    if zero_pad:\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "    return torch.tensor(input_ids).unsqueeze(0), input_mask\n",
    "                     \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "282360bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        utterance = self.data.text[index]\n",
    "        label = self.data.label[index]\n",
    "        X, _  = prepare_features(utterance)\n",
    "        y = label_to_inx[self.data.label[index]]\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3390e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(pred, lst_true):\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "     \n",
    "    acc = accuracy_score(lst_true, pred)\n",
    "    f1_micro = f1_score(lst_true, pred, average='micro')\n",
    "    f1_macro = f1_score(lst_true, pred, average='macro')\n",
    "    \n",
    "    return acc, f1_micro, f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aee17e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_inx = {'unsustainable':0,'sustainable':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "79f4c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b10323ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if errors: /tmp/.cache/torch permission just give sudo chmod -R a+rw xxx/xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "395c6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b4fc0a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.11.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b2fc06dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6cf9f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b615cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467d7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6cf1d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_valid = pd.read_csv('../data/valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b54805d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Intents(df_train)\n",
    "testing_set = Intents(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1cc7801e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,   100,  1729,   597,  1364,     7,  8924,  3942,  4918,     8,\n",
       "           4921,     7,  7677, 35552,    31,  9092,     8,  9440,  1787,  9781,\n",
       "             11,   391,   730,     4,     2,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 1)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(training_set), len(testing_set)\n",
    "t, l = training_set[0]\n",
    "t, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "58af30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 16,\n",
    "          'shuffle': True,\n",
    "          'drop_last': False,\n",
    "          'num_workers': 0}\n",
    "# params = {'batch_size': 16,\n",
    "#           'shuffle': True,\n",
    "#           'drop_last': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "97a61696",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(dataset=training_set, **params)\n",
    "testing_loader = DataLoader(dataset=testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cbff48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = iter(training_loader)\n",
    "testing_loader = iter(testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "86f48741",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-05\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e3961870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# inp = training_set.__getitem__(0)[0].cuda()\n",
    "inp = training_set.__getitem__(0)[0]\n",
    "output = model(inp)[0]\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a00cd4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60da26c2226f4e21899b2ce6245a71a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n",
      "EPOCH -- 1\n",
      "EPOCH -- 2\n",
      "EPOCH -- 3\n",
      "EPOCH -- 4\n",
      "EPOCH -- 5\n",
      "EPOCH -- 6\n",
      "EPOCH -- 7\n",
      "EPOCH -- 8\n",
      "EPOCH -- 9\n",
      "EPOCH -- 10\n",
      "EPOCH -- 11\n",
      "EPOCH -- 12\n",
      "EPOCH -- 13\n",
      "EPOCH -- 14\n",
      "EPOCH -- 15\n",
      "EPOCH -- 16\n",
      "EPOCH -- 17\n",
      "EPOCH -- 18\n",
      "EPOCH -- 19\n",
      "EPOCH -- 20\n",
      "EPOCH -- 21\n",
      "EPOCH -- 22\n",
      "EPOCH -- 23\n",
      "EPOCH -- 24\n",
      "EPOCH -- 25\n",
      "EPOCH -- 26\n",
      "EPOCH -- 27\n",
      "EPOCH -- 28\n",
      "EPOCH -- 29\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 30\n",
    "model = model.train()\n",
    "for epoch in tqdm.notebook.tqdm(range(max_epochs)):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, batch in enumerate(training_loader):\n",
    "      sent, label = batch[0], batch[1]\n",
    "      optimizer.zero_grad()\n",
    "      sent = sent.squeeze(0)\n",
    "      if torch.cuda.is_available():\n",
    "        sent = sent.cuda()\n",
    "        label = label.cuda()\n",
    "      output = model(sent)[0]\n",
    "      _, predicted = torch.max(output, 1)\n",
    "      \n",
    "      loss = loss_function(output, label)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      if i%100 == 0:\n",
    "          correct = 0\n",
    "          total = 0\n",
    "          for sent, label in testing_loader:\n",
    "              sent = sent.squeeze(0)\n",
    "              if torch.cuda.is_available():\n",
    "                sent = sent.cuda()\n",
    "                label = label.cuda()\n",
    "              output = model.forward(sent)[0]\n",
    "              _, predicted = torch.max(output.data, 1)\n",
    "              total += label.size(0)\n",
    "              correct += (predicted.cpu() == label.cpu()).sum()\n",
    "          accuracy = 100.00 * correct.numpy() / total\n",
    "          print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2ca6e307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n",
      "EPOCH -- 1\n",
      "EPOCH -- 2\n",
      "EPOCH -- 3\n",
      "EPOCH -- 4\n",
      "EPOCH -- 5\n",
      "EPOCH -- 6\n",
      "EPOCH -- 7\n",
      "EPOCH -- 8\n",
      "EPOCH -- 9\n",
      "EPOCH -- 10\n",
      "EPOCH -- 11\n",
      "EPOCH -- 12\n",
      "EPOCH -- 13\n",
      "EPOCH -- 14\n",
      "EPOCH -- 15\n",
      "EPOCH -- 16\n",
      "EPOCH -- 17\n",
      "EPOCH -- 18\n",
      "EPOCH -- 19\n",
      "EPOCH -- 20\n",
      "EPOCH -- 21\n",
      "EPOCH -- 22\n",
      "EPOCH -- 23\n",
      "EPOCH -- 24\n",
      "EPOCH -- 25\n",
      "EPOCH -- 26\n",
      "EPOCH -- 27\n",
      "EPOCH -- 28\n",
      "EPOCH -- 29\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 30\n",
    "model = model.train()\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, batch in enumerate(training_loader):\n",
    "        sent, label = batch[0], batch[1]\n",
    "        optimizer.zero_grad()\n",
    "        sent = sent.squeeze(1)\n",
    "        if torch.cuda.is_available():\n",
    "            sent = sent.cuda()\n",
    "            label = label.cuda()\n",
    "        output = model(sent)[0]\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for sent, label in testing_loader:\n",
    "                sent = sent.squeeze(1)\n",
    "                if torch.cuda.is_available():\n",
    "                    sent = sent.cuda()\n",
    "                    label = label.cuda()\n",
    "                output = model.forward(sent)[0]\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "422d280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "lst_prediction =[]\n",
    "lst_test = list(df_valid['text'])\n",
    "model.eval()\n",
    "for msg in lst_test:\n",
    "    input_msg, _ = prepare_features(msg)\n",
    "    if torch.cuda.is_available():\n",
    "        input_msg = input_msg.cuda()\n",
    "        output = model(input_msg)[0]\n",
    "        outputs.append(output)\n",
    "        _, pred_label = torch.max(output.data, 1)\n",
    "        prediction=list(label_to_inx.keys())[pred_label]\n",
    "        lst_prediction.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1eb97a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [o.to('cpu').detach().numpy().copy() for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3acaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "157ed40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_class = ['unsustainable','sustainable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "638fd11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2 = [] \n",
    "[predictions2.append([x[1] for x in [sorted(zip(example[0], lst_class), reverse=True)][0]]) for example in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c11f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5a9e7573",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = [a[0] for a in predictions2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5b0aecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_true = list(df_valid['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "46901218",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [266, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ck/5sxp2x1n4d534l6w14v0mvyr0000gn/T/ipykernel_2462/3416779358.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_micro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_macro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/ck/5sxp2x1n4d534l6w14v0mvyr0000gn/T/ipykernel_2462/3212617033.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(pred, lst_true)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mf1_micro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mf1_macro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniforge3/envs/pt39/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniforge3/envs/pt39/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniforge3/envs/pt39/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [266, 0]"
     ]
    }
   ],
   "source": [
    "acc, f1_micro, f1_macro = get_result(predictions3, lst_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6324c451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8533834586466166, 0.8533834586466166, 0.8518571408171134)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, f1_micro, f1_macro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc26bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16905fb836dc46b5d0f107a558ba9782ff628de99dc7e57216a87d47ef49f198"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('pt39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
